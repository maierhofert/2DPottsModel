# measurements before t0
# noise before t0 is Gaussian with expectation mu_0 and variance sigma_0
# assume for simplicity mu_0 =0
mu_0 = 0
sigma_0 = 1
# flat with Gaussian noise
y[t < t0] = rnorm(mean = mu_0, sd = sigma_0, n = sum(t < t0))
# check out what happened
plot(t, y)
abline(v=t0, col = "green")
t
# Simulate some data
set.seed(42)
# time goes from 0 to 1
t = seq(0, 1, 0.01)
t
# sample t0
# expectation of beta distribtuion is shape1 / (shape1 + shape2)
# a.k.a. alpha and beta
shape1 = 1
shape2 = 5
# randomly sample an observation for t0
t0 = rbeta(n = 1, shape1 = 1, shape2 = 10)
# this is the distribution with the t0
plot(t, dbeta(t, shape1, shape2), ylab="density", type ="l")
abline(v=t0, col = "green")
# initialize measurements
y = rep(0, length(t))
# measurements before t0
# noise before t0 is Gaussian with expectation mu_0 and variance sigma_0
# assume for simplicity mu_0 =0
mu_0 = 0
sigma_0 = 1
# flat with Gaussian noise
y[t < t0] = rnorm(mean = mu_0, sd = sigma_0, n = sum(t < t0))
# check out inital measurements
plot(t, y)
abline(v=t0, col = "green")
t0
# Simulate some data
set.seed(42)
# time goes from 0 to 1
t = seq(0, 1, 0.01)
t
# sample t0
# expectation of beta distribtuion is shape1 / (shape1 + shape2)
# a.k.a. alpha and beta
shape1 = 1
shape2 = 5
# randomly sample an observation for t0
t0 = rbeta(n = 1, shape1 = shape1, shape2 = shape2)
# this is the distribution with the t0
plot(t, dbeta(t, shape1, shape2), ylab="density", type ="l")
abline(v=t0, col = "green")
# initialize measurements
y = rep(0, length(t))
# measurements before t0
# noise before t0 is Gaussian with expectation mu_0 and variance sigma_0
# assume for simplicity mu_0 =0
mu_0 = 0
sigma_0 = 1
# flat with Gaussian noise
y[t < t0] = rnorm(mean = mu_0, sd = sigma_0, n = sum(t < t0))
# check out inital measurements
plot(t, y)
abline(v=t0, col = "green")
?logistic
??logistic
logistic = function(x, L, k, x0) {
return(L / (1 + exp(-k * (x - x0)))
}
logistic = function(x, L, k, x0) {
return(L / (1 + exp(-k * (x - x0))))
}
# sample values from after t0
y[t > t0] = rnorm(n = sum(t > t0),
mean = logistic(x = t[t > t0], L = L, k = k, x0 = x0))
# simulation parameters
# upper bound L
L = 5
# steepness k
k = 1
# midpoint of curve x0
x0 = 0.5
# sample values from after t0
y[t > t0] = rnorm(n = sum(t > t0),
mean = logistic(x = t[t > t0], L = L, k = k, x0 = x0))
# check out all measurements
plot(t, y)
abline(v=t0, col = "green")
# simulation parameters
# upper bound L
L = 5
# steepness k
k = 1
# midpoint of curve x0
x0 = t0 + 0.1
# sample values from after t0
y[t > t0] = rnorm(n = sum(t > t0),
mean = logistic(x = t[t > t0], L = L, k = k, x0 = x0))
# check out all measurements
plot(t, y)
abline(v=t0, col = "green")
# simulation parameters
# upper bound L
L = 5
# steepness k
k = 5
# midpoint of curve x0
x0 = t0 + 0.1
# sample values from after t0
y[t > t0] = rnorm(n = sum(t > t0),
mean = logistic(x = t[t > t0], L = L, k = k, x0 = x0))
# check out all measurements
plot(t, y)
abline(v=t0, col = "green")
# start of curve is at t0
t0 = 0.3
# initialize measurements
y = rep(0, length(t))
# measurements before t0
# noise before t0 is Gaussian with expectation mu_0 and variance sigma_0
# assume for simplicity mu_0 =0
mu_0 = 0
sigma_0 = 1
# flat with Gaussian noise
y[t < t0] = rnorm(mean = mu_0, sd = sigma_0, n = sum(t < t0))
# check out inital measurements
plot(t, y)
abline(v=t0, col = "green")
# measurements after t0
# noise after t0 is Gaussian with expectation 0 and variance sigma_1
sigma_1 = 1
# Simulate some data
set.seed(42)
# time goes from 0 to 1
t = seq(0, 1, 0.01)
t
# start of curve is at t0
t0 = 0.3
# initialize measurements
y = rep(0, length(t))
# measurements before t0
# noise before t0 is Gaussian with expectation mu_0 and variance sigma_0
# assume for simplicity mu_0 =0
mu_0 = 0
sigma_0 = 1
# flat with Gaussian noise
y[t < t0] = rnorm(mean = mu_0, sd = sigma_0, n = sum(t < t0))
# check out inital measurements
plot(t, y)
abline(v=t0, col = "green")
# measurements after t0
# noise after t0 is Gaussian with expectation 0 and variance sigma_1
sigma_1 = 1
# measurements after t0 follow logistic function
# use this helper function
logistic = function(x, L, k, x0) {
return(L / (1 + exp(-k * (x - x0))))
}
# simulation parameters
# upper bound L
L = 5
# steepness k
k = 5
# midpoint of curve x0
x0 = t0 + 0.1
# sample values from after t0
y[t > t0] = rnorm(n = sum(t > t0),
mean = logistic(x = t[t > t0], L = L, k = k, x0 = x0))
# check out all measurements
plot(t, y)
abline(v=t0, col = "green")
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
knitr::opts_chunk$set(echo = TRUE)
plot(t, y)
lines(t, true_y, col = "blue")
# initialize measurements
y = rep(0, length(t))
true_y = rep(0, length(t))
# measurements before t0
# noise before t0 is Gaussian with expectation mu_0 and variance sigma_0
# assume for simplicity mu_0 =0
mu_0 = 0
sigma_0 = 1
# flat with Gaussian noise
y[t < t0] = rnorm(mean = mu_0, sd = sigma_0, n = sum(t < t0))
true_y[t < t0] = 0
# check out inital measurements
plot(t, y)
lines(t, true_y, col = "blue")
abline(v=t0, col = "green")
true_y[t > t0] = logistic(x = t[t > t0], L = L, k = k, x0 = x0)
# check out all measurements
plot(t, y)
lines(t, true_y, col = "blue")
abline(v=t0, col = "green")
# sample values from after t0
y[t > t0] = rnorm(n = sum(t > t0),
mean = logistic(x = t[t > t0], L = L, k = k, x0 = x0))
true_y[t > t0] = logistic(x = t[t > t0], L = L, k = k, x0 = x0)
# check out all measurements
plot(t, y)
lines(t, true_y, col = "blue")
abline(v=t0, col = "green")
# simulation parameters
# upper bound L
L = 5
# steepness k
k = 5
# midpoint of curve x0
x0 = t0
# sample values from after t0
y[t > t0] = rnorm(n = sum(t > t0),
mean = logistic(x = t[t > t0], L = L, k = k, x0 = x0))
true_y[t > t0] = logistic(x = t[t > t0], L = L, k = k, x0 = x0)
# check out all measurements
plot(t, y)
lines(t, true_y, col = "blue")
abline(v=t0, col = "green")
shifted_logistic = function(x, L, k, x0) {
return(L / (1 + exp(-k * (x - x0))) - L / 2)
}
shifted_logistic = function(x, L, k, x0) {
return(L / (1 + exp(-k * (x - x0))) - L / 2)
}
# simulation parameters
# upper bound L
L = 5
# steepness k
k = 5
# midpoint of curve x0
x0 = t0
# sample values from after t0
y[t > t0] = rnorm(n = sum(t > t0),
mean = shifted_logistic(x = t[t > t0], L = L, k = k, x0 = x0))
true_y[t > t0] = shifted_logistic(x = t[t > t0], L = L, k = k, x0 = x0)
# check out all measurements
plot(t, y)
lines(t, true_y, col = "blue")
abline(v=t0, col = "green")
shifted_logistic = function(x, L, k, x0) {
return(2 * L / (1 + exp(-k * (x - x0))) - L / 2)
}
# simulation parameters
# upper bound L
L = 5
# steepness k
k = 5
# midpoint of curve x0
x0 = t0
# sample values from after t0
y[t > t0] = rnorm(n = sum(t > t0),
mean = shifted_logistic(x = t[t > t0], L = L, k = k, x0 = x0))
true_y[t > t0] = shifted_logistic(x = t[t > t0], L = L, k = k, x0 = x0)
# check out all measurements
plot(t, y)
lines(t, true_y, col = "blue")
abline(v=t0, col = "green")
shifted_logistic = function(x, L, k, x0) {
return(2 * (L / (1 + exp(-k * (x - x0))) - L / 2))
}
# simulation parameters
# upper bound L
L = 5
# steepness k
k = 5
# midpoint of curve x0
x0 = t0
# sample values from after t0
y[t > t0] = rnorm(n = sum(t > t0),
mean = shifted_logistic(x = t[t > t0], L = L, k = k, x0 = x0))
true_y[t > t0] = shifted_logistic(x = t[t > t0], L = L, k = k, x0 = x0)
# check out all measurements
plot(t, y)
lines(t, true_y, col = "blue")
abline(v=t0, col = "green")
# sample t0
# expectation of beta distribtuion is shape1 / (shape1 + shape2)
# a.k.a. alpha and beta
shape1 = 1
shape2 = 5
# randomly sample an observation for t0
t0 = rbeta(n = 1, shape1 = shape1, shape2 = shape2)
# this is the distribution with the t0
plot(t, dbeta(t, shape1, shape2), ylab="density", type ="l")
abline(v=t0, col = "green")
pkgbuild::has_build_tools(debug = TRUE)
# Load rstan package
library(rstan)
# Avoid unnecessary recompiling
rstan_options(auto_write = TRUE)
# Set random seed (today's date)
set.seed(2018-07-04)
# 80 data points
n <- 80
# Generate 'age of acquisition' data (integers between 1 and 50)
AOA <- sample(1:50, size = n, replace = TRUE)
# Set breakpoint at some plausible age
BP <- 10
# Generate average values on GJT (~ 'grammar test') outcome
meanGJT <- ifelse(AOA < BP,
176 - 1.2 * (AOA - BP),
176 - 0.4 * (AOA - BP))
plot(AOA, meanGJT, main = "Underlying function")
segments(x0 = BP, y0 = 0, y1 = 176, lty = 2)
segments(x0 = 0, x1 = BP, y0 = 176, lty = 2)
# Generate observed values
error <- 3
obsGJT <- rnorm(n = n, mean = meanGJT, sd = error)
plot(AOA, obsGJT, main = "Observed data")
model_bp <- '
model_bp <- '
// You need to specify the kind of input data, incl. number of observations.
data {
int<lower=1> N;  // total number of observations (integer); at least 1
real GJT[N];     // outcome variable with N elements (real-valued)
real AOA[N];     // predictor variable with N elements (real-valued)
}
// the parameters to be estimated from the data
parameters {
real intercept;                 // = predicted outcome at breakpoint
real slope_before;              // slope before the breakpoint
real slope_after;               // slope after the breakpoint
real<lower = 1, upper = 20> bp; // the breakpoint age, with some constraints
real<lower = 0> error;          // standard deviation of residuals
//  (always positive, hence <lower = 0>)
}
// Functions of estimated parameters.
transformed parameters{
vector[N] conditional_mean; // the estimated average GJT for each AOA observation
real slope_difference;      // the difference between slope_after and slope_before
slope_difference = slope_after - slope_before;
// conditional_mean depends on whether AOA is before or after bp
for (i in 1:N) {
if (AOA[i] < bp) {
conditional_mean[i] = intercept + slope_before * (AOA[i] - bp);
} else {
conditional_mean[i] = intercept + slope_after * (AOA[i] - bp);
}
}
}
// The model itself specifies how the data are expected to have
// been generated and what the prior expectations for the model parameters are.
model {
// Set priors
intercept ~ normal(150, 25);  // Average GJT at breakpoint
slope_before ~ normal(0, 5);  // Slope before breakpoint
slope_after ~ normal(0, 5);   // Slope after breakpoint
bp ~ normal(12, 6);           // Breakpoint age, pretty wide, but somewhere in childhood/puberty
error ~ normal(0, 20);        // Residual error, likely between 0 and 2*20
// How the data are expected to have been generated:
// normal distribution with mu = conditional_mean and
// std = error, estimated from data.
for (i in 1:N) {
GJT[i] ~ normal(conditional_mean[i], error);
}
}
generated quantities {
vector[N] sim_GJT;               // Simulate new data using estimated parameters.
vector[N] log_lik;               // Useful for model comparisons; not done here.
vector[50] sim_conditional_mean; // Useful for plotting.
// Compute conditional means for AOAs between 1 and 50.
for (i in 1:50) {
if (i < bp) {
sim_conditional_mean[i] = intercept + slope_before * (i - bp);
} else {
sim_conditional_mean[i] = intercept + slope_after * (i - bp);
}
}
for (i in 1:N) {
sim_GJT[i] = normal_rng(conditional_mean[i], error);
log_lik[i] = normal_lpdf(GJT[i] | conditional_mean[i], error);
}
}
'
data_list <- list(
AOA = AOA,
GJT = obsGJT,
N = length(AOA)
)
fit_bp_sim <- stan(model_code = model_bp,
data = data_list)
knitr::opts_chunk$set(echo = TRUE)
# Load rstan package
library(rstan)
# Avoid unnecessary recompiling
rstan_options(auto_write = TRUE)
# Set random seed (today's date)
set.seed(2018-07-04)
# 80 data points
n <- 80
# Generate 'age of acquisition' data (integers between 1 and 50)
AOA <- sample(1:50, size = n, replace = TRUE)
# Set breakpoint at some plausible age
BP <- 10
# Generate average values on GJT (~ 'grammar test') outcome
meanGJT <- ifelse(AOA < BP,
176 - 1.2 * (AOA - BP),
176 - 0.4 * (AOA - BP))
plot(AOA, meanGJT, main = "Underlying function")
segments(x0 = BP, y0 = 0, y1 = 176, lty = 2)
segments(x0 = 0, x1 = BP, y0 = 176, lty = 2)
# Generate observed values
error <- 3
obsGJT <- rnorm(n = n, mean = meanGJT, sd = error)
plot(AOA, obsGJT, main = "Observed data")
model_bp <- '
// You need to specify the kind of input data, incl. number of observations.
data {
int<lower=1> N;  // total number of observations (integer); at least 1
real GJT[N];     // outcome variable with N elements (real-valued)
real AOA[N];     // predictor variable with N elements (real-valued)
}
// the parameters to be estimated from the data
parameters {
real intercept;                 // = predicted outcome at breakpoint
real slope_before;              // slope before the breakpoint
real slope_after;               // slope after the breakpoint
real<lower = 1, upper = 20> bp; // the breakpoint age, with some constraints
real<lower = 0> error;          // standard deviation of residuals
//  (always positive, hence <lower = 0>)
}
// Functions of estimated parameters.
transformed parameters{
vector[N] conditional_mean; // the estimated average GJT for each AOA observation
real slope_difference;      // the difference between slope_after and slope_before
slope_difference = slope_after - slope_before;
// conditional_mean depends on whether AOA is before or after bp
for (i in 1:N) {
if (AOA[i] < bp) {
conditional_mean[i] = intercept + slope_before * (AOA[i] - bp);
} else {
conditional_mean[i] = intercept + slope_after * (AOA[i] - bp);
}
}
}
// The model itself specifies how the data are expected to have
// been generated and what the prior expectations for the model parameters are.
model {
// Set priors
intercept ~ normal(150, 25);  // Average GJT at breakpoint
slope_before ~ normal(0, 5);  // Slope before breakpoint
slope_after ~ normal(0, 5);   // Slope after breakpoint
bp ~ normal(12, 6);           // Breakpoint age, pretty wide, but somewhere in childhood/puberty
error ~ normal(0, 20);        // Residual error, likely between 0 and 2*20
// How the data are expected to have been generated:
// normal distribution with mu = conditional_mean and
// std = error, estimated from data.
for (i in 1:N) {
GJT[i] ~ normal(conditional_mean[i], error);
}
}
generated quantities {
vector[N] sim_GJT;               // Simulate new data using estimated parameters.
vector[N] log_lik;               // Useful for model comparisons; not done here.
vector[50] sim_conditional_mean; // Useful for plotting.
// Compute conditional means for AOAs between 1 and 50.
for (i in 1:50) {
if (i < bp) {
sim_conditional_mean[i] = intercept + slope_before * (i - bp);
} else {
sim_conditional_mean[i] = intercept + slope_after * (i - bp);
}
}
for (i in 1:N) {
sim_GJT[i] = normal_rng(conditional_mean[i], error);
log_lik[i] = normal_lpdf(GJT[i] | conditional_mean[i], error);
}
}
'
data_list <- list(
AOA = AOA,
GJT = obsGJT,
N = length(AOA)
)
data_list
fit_bp_sim <- stan(model_code = model_bp,
data = data_list)
fit_bp_sim
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
install.packages("rstan", type = "source")
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
remotes::install_github("stan-dev/rstan", ref = "develop",
subdir = "rstan/rstan", build_opts = "")
install.packages(remotes)
install.packages("remotes")
remotes::install_github("stan-dev/rstan", ref = "develop",
subdir = "rstan/rstan", build_opts = "")
fx <- inline::cxxfunction( signature(x = "integer", y = "numeric" ) , '
return ScalarReal( INTEGER(x)[0] * REAL(y)[0] ) ;
' ) fx( 2L, 5 ) # should be 10
fx <- inline::cxxfunction( signature(x = "integer", y = "numeric" ) , '
return ScalarReal( INTEGER(x)[0] * REAL(y)[0] ) ;
' )
install.packages("rstan")
# Load rstan package
library(rstan)
source('~/Box/TestRstan.R', echo=TRUE)
reticulate::repl_python()
setwd("~/Box/202C/2DPottsModel")
reticulate::repl_python()
